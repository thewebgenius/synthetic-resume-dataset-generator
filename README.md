ğŸ“Š Synthetic Resume Dataset
<p> Due to <strong>privacy, legal, and ethical constraints</strong>, large-scale labeled resume datasets are not publicly available. To overcome this limitation, this project uses a <strong>fully synthetic resume dataset</strong> designed to replicate real-world resume layouts while remaining safe, scalable, and reproducible. </p> <hr> <h3>ğŸ“ Dataset Overview</h3> <ul> <li><strong>Type:</strong> Synthetic document images</li> <li><strong>Domain:</strong> Resume / CV layout analysis</li> <li><strong>Total samples:</strong> 1000+ resumes</li> <li><strong>Formats:</strong> PDF â†’ Image (PNG/JPEG)</li> <li><strong>Annotation format:</strong> YOLO (bounding boxes)</li> </ul> <p> Each resume is generated programmatically and annotated automatically, enabling rapid dataset scaling without manual labeling. </p> <hr> <h3>ğŸ·ï¸ Layout Classes</h3> <p>The dataset contains bounding box annotations for the following resume sections:</p> <ul> <li><code>header</code></li> <li><code>education</code></li> <li><code>skills</code></li> <li><code>projects</code></li> <li><code>experience</code></li> <li><code>hobbies</code></li> </ul> <p> <strong>Note:</strong> The focus is on <em>layout detection</em>, not text recognition or semantic understanding. </p> <hr> <h3>âš™ï¸ Synthetic Data Generation Pipeline</h3> <ol> <li> <strong>Template Design</strong><br> HTML and CSS based resume templates designed to reflect industry-style layouts with controlled variations. </li> <li> <strong>Content Generation</strong><br> Programmatic generation of realistic resume content (education, skills, projects, experience). </li> <li> <strong>Rendering Pipeline</strong><br> Conversion from HTML â†’ PDF â†’ Image to simulate real document workflows. </li> <li> <strong>Annotation Generation</strong><br> Automatic creation of YOLO-format bounding box annotations aligned with visual layout sections. </li> <li> <strong>Robustness Enhancements</strong><br> Noise injection (blur, compression artifacts, distortions) to improve CNN generalization. </li> </ol> <hr> <h3>ğŸ§  Why Synthetic Data?</h3> <p> Synthetic data is particularly effective for <strong>document AI</strong> tasks because CNNs learn <strong>visual structure</strong> such as layout, alignment, spacing, and hierarchy â€” not semantic meaning. </p> <ul> <li>No privacy or compliance risks</li> <li>Perfect annotation accuracy</li> <li>Balanced class distributions</li> <li>Scalable dataset generation</li> <li>Faster experimentation cycles</li> </ul> <hr> <h3>ğŸ¯ Intended Use</h3> <p>This dataset is intended for:</p> <ul> <li>Resume and document layout detection</li> <li>Training object detection models (YOLO, Faster R-CNN, etc.)</li> <li>Pre-processing before OCR or NLP pipelines</li> </ul> <p> <strong>Not intended for:</strong> Direct text extraction or semantic analysis. </p> <hr> <h3>ğŸ“¦ Dataset Availability</h3> <p> To keep the repository lightweight, only <strong>sample data</strong> is included. </p> <p> The complete dataset (1000+ images and annotations) can be shared separately upon request. </p>
